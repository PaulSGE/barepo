{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgbQd1u9QSmK"
   },
   "source": [
    "# **IMPORT LIBRARY FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "2iDeOWZGyFaZ"
   },
   "outputs": [],
   "source": [
    "#pip install tsai[extras]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ObcLg1kQfFf"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/fastai/fastai\n",
    "#!pip install -e \"fastai[dev]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoTMIu7oQke-"
   },
   "outputs": [],
   "source": [
    "# **************** UNCOMMENT AND RUN THIS CELL IF YOU NEED TO INSTALL/ UPGRADE TSAI ****************\n",
    "#stable = False # Set to True for latest pip version or False for main branch in GitHub\n",
    "#!pip install {\"tsai -U\" if stable else \"git+https://github.com/timeseriesAI/tsai.git\"} >> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VO8DrbgIQvua"
   },
   "outputs": [],
   "source": [
    "import tsai\n",
    "import fastai\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVOKQviS--DB"
   },
   "outputs": [],
   "source": [
    "### Set float to 2 dec\n",
    "#precision attr geändert\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3LyQGQXZsXm"
   },
   "outputs": [],
   "source": [
    "from tsai.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qi72Uu3HXvYW"
   },
   "outputs": [],
   "source": [
    "__all__ = ['TimeSplitter', 'RandomSplitter', 'check_overlap', 'check_splits_overlap', 'leakage_finder', 'balance_idx',\n",
    "           'TrainValidTestSplitter', 'plot_splits', 'get_splits', 'get_walk_forward_splits', 'TSSplitter',\n",
    "           'get_predefined_splits', 'combine_split_data', 'get_splits_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFeVuGj9REYW"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_o1Zn8WiAwD9"
   },
   "outputs": [],
   "source": [
    "### Set path to the correct folder\n",
    "\n",
    "path = (r'/content/drive/MyDrive/ColabNotebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5NLFtbUAyoQ"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/MyDrive/ColabNotebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5G6Hqy3Sit9"
   },
   "source": [
    "# **Open Files Create DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnavOgLhRVI5"
   },
   "outputs": [],
   "source": [
    "### Every model (9 models) needs to be modelled serperately\n",
    "### --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# 1)\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/Honda_Clarity_Electric/Honda_Clarity_100.csv\")\n",
    "\n",
    "#2)\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/Chevy_Bolt/ChevyBolt_100.csv\")\n",
    "\n",
    "# 3)\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/VW_eGolf/VW_100.csv\")\n",
    "\n",
    "# 4)\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/Tesla_Model_3/Tesla_100.csv\")\n",
    "\n",
    "# 5)\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/Nissan_Leaf/Nissan_100.csv\")\n",
    "\n",
    "# 6)\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/Kia_Soul/KiaSoul_100.csv\")\n",
    "\n",
    "# 7)\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/Kia_e-Niro/KiaEniro_100.csv\")\n",
    "\n",
    "# 8)\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/Hyundai_Kona_Electric/HyundaiKonaElectric_100.csv\")\n",
    "\n",
    "# 9)\n",
    "#df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/Ford_Focus/FordFocus_100.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iadave4Km_a"
   },
   "outputs": [],
   "source": [
    "#for i,chunk in enumerate(pd.read_csv('../data/september_ev.csv', chunksize=302402)):\n",
    " #   chunk.to_csv('../data/september_{}.csv'.format(i), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwfVzFsWg56u"
   },
   "outputs": [],
   "source": [
    "### DF ANALYSIS - ROWS AND COLUMNS\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-Y47_245BlF"
   },
   "outputs": [],
   "source": [
    "### DF ANALYSIS - COLUMN DATA TYPES\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGkQFrXQO1rS"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44WjByLjowv6"
   },
   "outputs": [],
   "source": [
    "### Create 70% column\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "content = 0\n",
    "\n",
    "df.insert(7, '70_battery', content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_I1G62otpFnJ"
   },
   "outputs": [],
   "source": [
    "### Create 100% column\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "content = 0\n",
    "\n",
    "df.insert(8, '100_battery', content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEGcEB-xjifq"
   },
   "outputs": [],
   "source": [
    "### Save dataframe pre padding data frame to csv file\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "#df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/Tesla_Model_3/Tesla_latest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sObPplUjp_7"
   },
   "outputs": [],
   "source": [
    "### Charge Station dataset to variable - border\n",
    "### -----------------------------------------------------------\n",
    "#Altes Sheet hat nicht existiert\n",
    "border = pd.read_excel(\"ChargeStations.xlsx\", sheet_name=\"border communities\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMO8Xkykuk3I"
   },
   "outputs": [],
   "source": [
    "df['start_datetime_combined'] = df['start_date'].astype(str) + ' ' + df['start_time'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfBqdBdXvT1x"
   },
   "outputs": [],
   "source": [
    "df['end_datetime_combined'] = df['end_date'].astype(str) + ' ' + df['end_time'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1K6Ym_CuyY1"
   },
   "outputs": [],
   "source": [
    "df['start_datetime'] = pd.to_datetime(\n",
    "    df['start_datetime_combined'],\n",
    "    format=\"%d/%m/%Y %H:%M\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryjHsXtFvXN9"
   },
   "outputs": [],
   "source": [
    "df['end_datetime'] = pd.to_datetime(\n",
    "    df['end_datetime_combined'],\n",
    "    format=\"%d/%m/%Y %H:%M\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfMFgB-P449D"
   },
   "outputs": [],
   "source": [
    "### change start and end datetime to correct data types\n",
    "### NICHT AUSFÜHREN!\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "#df['start_datetime'] = pd.to_datetime(df['start_datetime'])\n",
    "#df['end_datetime'] = pd.to_datetime(df['end_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxPGsMdq45ud"
   },
   "outputs": [],
   "source": [
    "### Feature engineer day, month, hour, and duration of trip\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df[\"start_daymonth\"] = df[\"start_datetime\"].dt.month\n",
    "df[\"start_dayday\"] = df[\"start_datetime\"].dt.day\n",
    "df[\"start_dayhour\"] = df[\"start_datetime\"].dt.hour\n",
    "\n",
    "df[\"end_daymonth\"] = df[\"end_datetime\"].dt.month\n",
    "df[\"end_dayday\"] = df[\"end_datetime\"].dt.day\n",
    "df[\"end_dayhour\"] = df[\"end_datetime\"].dt.hour\n",
    "\n",
    "df[\"duration\"] = (df[\"end_datetime\"] - df[\"start_datetime\"]).dt.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfAO8331C9AL"
   },
   "outputs": [],
   "source": [
    "### DF analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNSLeojO8RGd"
   },
   "outputs": [],
   "source": [
    "### Drop columns\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "to_remove = [\"ev_model\", \"day\", 'period']\n",
    "df.drop(to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhHt_6NuUY6M"
   },
   "outputs": [],
   "source": [
    "### Set border column variables\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "border.columns = [\"dropoff\", \"b1\",\"b2\",\"b3\",\"b4\",\"b5\",\"b6\",\"b7\",\"b8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKetmFW4VM0A"
   },
   "outputs": [],
   "source": [
    "### Check border head\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "border.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW6CAnw9Vi_A"
   },
   "outputs": [],
   "source": [
    "### Merge the model data and the boundary data into one dataframe\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df = df.merge(border, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bthYMd3KVtZJ"
   },
   "outputs": [],
   "source": [
    "### Check the dataframe\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBoBlWPoRNZy"
   },
   "outputs": [],
   "source": [
    "### Save dataframe pre padding data frame to csv file\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "#df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/Tesla_Model_3/Tesla_latest.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVw9JdYDiY1q"
   },
   "outputs": [],
   "source": [
    "### Replace NaN with 0\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5KXgbCyku7y"
   },
   "outputs": [],
   "source": [
    "### Check data types\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnQAzQV8PLkC"
   },
   "outputs": [],
   "source": [
    "### Using a dictionary convert border features from float64 to int64\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "convert_dict = {\n",
    "                'b1' : np.int64,\n",
    "                'b2' : np.int64,\n",
    "                'b3' : np.int64,\n",
    "                'b4' : np.int64,\n",
    "                'b5' : np.int64,\n",
    "                'b6' : np.int64,\n",
    "                'b7' : np.int64,\n",
    "                'b8' : np.int64,\n",
    "\n",
    "                }\n",
    "df = df.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVDa5Hu4pama"
   },
   "source": [
    "# **Create Batch Id Column and batches by 20_battery col = 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ci9RismjpY_x"
   },
   "outputs": [],
   "source": [
    "### Use 20_battery = 1 to split dataframe into batches by batch_id\n",
    "### copies batch_id to a batch id col\n",
    "### Create list of batches\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "batch_id = 0\n",
    "batches = []\n",
    "for ev_id in df['ev_id'].unique():\n",
    "    df_ev_data = df[df['ev_id']==ev_id].sort_values(\"start_datetime\").reset_index(drop=True)\n",
    "    ## Achtung hier wurde 20_battery auf charge gesetzt\n",
    "    index_positions = df_ev_data[df_ev_data[\"charge\"]==1].index\n",
    "    start_pos = df_ev_data.index[0]\n",
    "    for end_pos in index_positions:\n",
    "        new_batch = df_ev_data.iloc[start_pos:end_pos,:].copy()\n",
    "        new_batch[\"batch_id\"] = batch_id\n",
    "        batch_id = batch_id + 1\n",
    "        batches.append(new_batch)\n",
    "        start_pos = end_pos\n",
    "    #last batch append\n",
    "    final_batch = df_ev_data.iloc[end_pos:,:].copy()\n",
    "    final_batch.loc[:,\"batch_id\"] = batch_id\n",
    "    batch_id +=1\n",
    "    batches.append(final_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwpfRswHrgXr"
   },
   "outputs": [],
   "source": [
    "### Check how many batches in df\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyEGYcM2wTud"
   },
   "outputs": [],
   "source": [
    "### Concat batches into dataframe\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "batch_df = pd.concat(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92cp0N7awc3d"
   },
   "outputs": [],
   "source": [
    "### Check df rows and columns\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "batch_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpOErI6Xrs2L"
   },
   "outputs": [],
   "source": [
    "### ANALYSIS\n",
    "### Check 20 batches are unique (must be unique)\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "batch_df[\"batch_id\"].value_counts().iloc[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slAuPAJUsEm5"
   },
   "outputs": [],
   "source": [
    "### Only select batches that has at least 20 data points\n",
    "### Low value batches can creaste error when modelled\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "batch_counts = batch_df[\"batch_id\"].value_counts()\n",
    "selected_batches = list(batch_counts[batch_counts>=20].index)\n",
    "ver1_batch_df = batch_df[batch_df['batch_id'].isin(selected_batches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDE_mX3lsbYF"
   },
   "outputs": [],
   "source": [
    "### Check df rows and columns\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "ver1_batch_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPvdObIyshkP"
   },
   "outputs": [],
   "source": [
    "### Check unique how many batch ids\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "ver1_batch_df['batch_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KUQqITSODIG"
   },
   "outputs": [],
   "source": [
    "### Check the dataframe column names\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "ver1_batch_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8hvfSfLvpfx"
   },
   "source": [
    "# **Add Count to Batch ID in Preparation for Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGMt_Zbr8zjk"
   },
   "outputs": [],
   "source": [
    "### Data Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "ver1_batch_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMIYfHas84mY"
   },
   "outputs": [],
   "source": [
    "### Data Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "ver1_batch_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWXLS_bEv1Wf"
   },
   "outputs": [],
   "source": [
    "### GIVES ERROR BUT STILL WORKS?\n",
    "### Group by batch id and add numeric count to batches\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "ver1_batch_df[\"count\"] = 1 + ver1_batch_df.groupby(\"batch_id\").cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftvYInE-CYaQ"
   },
   "outputs": [],
   "source": [
    "### reset index rename new_df\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "new_df = ver1_batch_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-SE9pTkEWIP"
   },
   "outputs": [],
   "source": [
    "new_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmk2kqxGYRpG"
   },
   "outputs": [],
   "source": [
    "### ANALYSIS\n",
    "### count batches in df\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "new_df['batch_id'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EARKJM4Q0Xpf"
   },
   "outputs": [],
   "source": [
    "### TEST REDUCING THIS VALUE ???\n",
    "### Create list of batch_ids with unique counts\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df_s = new_df[\"batch_id\"].value_counts() <= 1060\n",
    "selected_batch = list(df_s[df_s].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RObM6TSZ0wVf"
   },
   "outputs": [],
   "source": [
    "### Save list contents to dataframe\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df = new_df[new_df['batch_id'].isin(selected_batch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1yqDHctAkN3"
   },
   "outputs": [],
   "source": [
    "### Save dataframe pre padding data frame to csv file\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "#df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/Tesla_Model_3/batched.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gc9QeTxdpZFm"
   },
   "source": [
    "# **ADD PADDING TO BATCHES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "rolVA-oPcLMo"
   },
   "outputs": [],
   "source": [
    "### Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "hFdHHfeThUsa"
   },
   "outputs": [],
   "source": [
    "### GIVES ERROR BUT WORKS?\n",
    "### DROP UNWANTED COLUMNS\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "to_remove = ['ev_id', 'model_id', 'duration', 'start_datetime', 'end_datetime']\n",
    "df.drop(to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "4LDkbz9AW9pe"
   },
   "outputs": [],
   "source": [
    "### Add padding to index 0\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "samp = df.iloc[[0]].copy()\n",
    "print(samp.columns)\n",
    "for c in samp.columns:\n",
    "    samp.loc[0,c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "YWDeTcRj9Hx7"
   },
   "outputs": [],
   "source": [
    "### Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "-AzpwIf62idJ"
   },
   "outputs": [],
   "source": [
    "### Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "xhI6LmWR2stv"
   },
   "outputs": [],
   "source": [
    "### Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df['batch_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "baBKvtA-2z_9"
   },
   "outputs": [],
   "source": [
    "### Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZSUUwArk6DK"
   },
   "outputs": [],
   "source": [
    "### Create times variable\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "batch_data = df['batch_id']\n",
    "times = len(batch_data)\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EvfKOVEkLWnF"
   },
   "outputs": [],
   "source": [
    "### Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TH2sbntn8G_R"
   },
   "outputs": [],
   "source": [
    "### Checking df for negative values\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "#df[df < 0].sum()\n",
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "#kleiner null check nur auf numbers und nicht alle im df anwenden\n",
    "result = df_numeric[df_numeric < 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GuEoslqIOmW"
   },
   "outputs": [],
   "source": [
    "### Checking for negative values\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "#(df < 0).apply(lambda x: any(x))\n",
    "df_numeric = df.select_dtypes(include=['number'])\n",
    "\n",
    "#Anwendung wieder nur auf number\n",
    "result = (df_numeric < 0).apply(lambda x: any(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdFN4DyAa6Hc"
   },
   "outputs": [],
   "source": [
    "### Replace negative values with 0\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "num = df._get_numeric_data()\n",
    "num[num < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsclXHLbLYJf"
   },
   "outputs": [],
   "source": [
    "### MAX LENGTH BATCH COUNT\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "df['batch_id'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymdRp54E1Rj3"
   },
   "outputs": [],
   "source": [
    "### PADDING\n",
    "### MUST USE MAX BATCH VALUE\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "%%time\n",
    "new_df = []\n",
    "for batch in df['batch_id'].unique()[:]:\n",
    "    to_append = []\n",
    "    batch_data = df[df['batch_id']==batch].copy()\n",
    "    times = 1060 - len(batch_data)\n",
    "    if times!=0:\n",
    "        samp_df = samp.loc[samp.index.repeat(times)].reset_index(drop=True)\n",
    "        samp_df[\"batch_id\"] = batch\n",
    "        to_append.append(samp_df)\n",
    "    to_append.append(batch_data)\n",
    "    batch_df = pd.concat(to_append)\n",
    "    new_df.append(batch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yksODcDH1Rev"
   },
   "outputs": [],
   "source": [
    "### Concat padded list save as df\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "padded_df = pd.concat(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpKaYkDS1RYd"
   },
   "outputs": [],
   "source": [
    "### Analysis\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "padded_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTi9HF_hn__t"
   },
   "outputs": [],
   "source": [
    "### SAVE DF TO CSV FILE\n",
    "### -----------------------------------------------------------\n",
    "\n",
    "padded_df.to_csv(\"/content/drive/MyDrive/ColabNotebooks/Tesla_Model_3/padded.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "170e21e9"
   },
   "source": [
    "# Task\n",
    "list_drive_contents(\"/content/drive/MyDrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b457eb39"
   },
   "source": [
    "## list_drive_contents\n",
    "\n",
    "### Subtask:\n",
    "List the contents of '/content/drive/MyDrive' to verify the exact directory name 'ColabNotebooks'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01c0179c"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "The contents of the `/content/drive/MyDrive` directory were listed to verify the existence and exact spelling of the 'ColabNotebooks' directory. The directory `ColabNotebooks` was successfully identified within `/content/drive/MyDrive`.\n",
    "\n",
    "### Insights or Next Steps\n",
    "* The next step is to navigate into the `ColabNotebooks` directory to proceed with further tasks.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
